{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>filepath</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_right.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "\n",
       "  Left-Diagnostic Keywords Right-Diagnostic Keywords  N  D  G  C  A  H  M  O  \\\n",
       "0                 cataract             normal fundus  0  0  0  1  0  0  0  0   \n",
       "\n",
       "                                            filepath labels  \\\n",
       "0  ../input/ocular-disease-recognition-odir5k/ODI...  ['N']   \n",
       "\n",
       "                     target     filename  \n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['filename'] == '0_right.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>filepath</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['D']</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['O']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>4_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "3      4           53        Male  4_left.jpg  4_right.jpg   \n",
       "3197   4           53        Male  4_left.jpg  4_right.jpg   \n",
       "\n",
       "         Left-Diagnostic Keywords          Right-Diagnostic Keywords  N  D  G  \\\n",
       "3     macular epiretinal membrane  mild nonproliferative retinopathy  0  1  0   \n",
       "3197  macular epiretinal membrane  mild nonproliferative retinopathy  0  1  0   \n",
       "\n",
       "      C  A  H  M  O                                           filepath labels  \\\n",
       "3     0  0  0  0  1  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
       "3197  0  0  0  0  1  ../input/ocular-disease-recognition-odir5k/ODI...  ['O']   \n",
       "\n",
       "                        target     filename  \n",
       "3     [0, 1, 0, 0, 0, 0, 0, 0]  4_right.jpg  \n",
       "3197  [0, 0, 0, 0, 0, 0, 0, 1]   4_left.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is to show that the dataset separate two image files in two rows\n",
    "df[df['Left-Fundus'] == '4_left.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the string slicing \n",
    "x = df['filename']\n",
    "name = x[0][:-4]\n",
    "name[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test imputing the image\n",
    "# y = df['filename'][0]\n",
    "# im = Image.open(f'./0_right_thumbnail.jpg')\n",
    "# list(im.getdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./preprocessed_images/{x}', 'r') as f:\n",
    "#     print(f)\n",
    "\n",
    "# The following grabs all the images from the preprocessed_images folder, and create thumbnail to reduce the data size \n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# create three lists(all, left, right) for the model later\n",
    "all_images = []\n",
    "all_images_left = []\n",
    "all_images_right = []\n",
    "def get_pixels(values):\n",
    "    im = Image.open(f'./preprocessed_images/{values}')\n",
    "    name = values[:-4]\n",
    "    im.thumbnail((128,128))\n",
    "    all_images.append(im)\n",
    "    if name[-5] == 'r':\n",
    "        all_images_right.append(im)\n",
    "    else:\n",
    "        all_images_left.append(im)\n",
    "    return im\n",
    "\n",
    "df['pixel_data'] = df['filename'].apply(lambda x: get_pixels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb260baa6d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# countplot to show the distribution of the dataset\n",
    "import seaborn as sns\n",
    "sns.countplot(df['y_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0]    2873\n",
       "[0, 1, 0, 0, 0, 0, 0, 0]    1608\n",
       "[0, 0, 0, 0, 0, 0, 0, 1]     708\n",
       "[0, 0, 0, 1, 0, 0, 0, 0]     293\n",
       "[0, 0, 1, 0, 0, 0, 0, 0]     284\n",
       "[0, 0, 0, 0, 1, 0, 0, 0]     266\n",
       "[0, 0, 0, 0, 0, 0, 1, 0]     232\n",
       "[0, 0, 0, 0, 0, 1, 0, 0]     128\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6392 entries, 0 to 6391\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   ID                         6392 non-null   int64 \n",
      " 1   Patient Age                6392 non-null   int64 \n",
      " 2   Patient Sex                6392 non-null   object\n",
      " 3   Left-Fundus                6392 non-null   object\n",
      " 4   Right-Fundus               6392 non-null   object\n",
      " 5   Left-Diagnostic Keywords   6392 non-null   object\n",
      " 6   Right-Diagnostic Keywords  6392 non-null   object\n",
      " 7   N                          6392 non-null   int64 \n",
      " 8   D                          6392 non-null   int64 \n",
      " 9   G                          6392 non-null   int64 \n",
      " 10  C                          6392 non-null   int64 \n",
      " 11  A                          6392 non-null   int64 \n",
      " 12  H                          6392 non-null   int64 \n",
      " 13  M                          6392 non-null   int64 \n",
      " 14  O                          6392 non-null   int64 \n",
      " 15  labels                     6392 non-null   object\n",
      " 16  target                     6392 non-null   object\n",
      " 17  filename                   6392 non-null   object\n",
      " 18  pixel_data                 6392 non-null   object\n",
      " 19  y_labels                   6392 non-null   object\n",
      " 20  bin_labels                 6392 non-null   int64 \n",
      " 21  c_labels                   6392 non-null   int64 \n",
      "dtypes: int64(12), object(10)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('filepath', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>...</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "      <th>pixel_data</th>\n",
       "      <th>y_labels</th>\n",
       "      <th>bin_labels</th>\n",
       "      <th>c_labels</th>\n",
       "      <th>combined_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "\n",
       "  Left-Diagnostic Keywords Right-Diagnostic Keywords  N  D  G  ...  M  O  \\\n",
       "0                 cataract             normal fundus  0  0  0  ...  0  0   \n",
       "\n",
       "   labels                    target     filename  \\\n",
       "0   ['N']  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg   \n",
       "\n",
       "                                          pixel_data y_labels bin_labels  \\\n",
       "0  <PIL.JpegImagePlugin.JpegImageFile image mode=...        N          0   \n",
       "\n",
       "  c_labels           combined_labels  \n",
       "0        0  [0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_list(data):\n",
    "    output_list = []\n",
    "    output_list.append(data['N'])\n",
    "    output_list.append(data['D'])\n",
    "    output_list.append(data['G'])\n",
    "    output_list.append(data['C'])\n",
    "    output_list.append(data['A'])\n",
    "    output_list.append(data['H'])\n",
    "    output_list.append(data['M'])\n",
    "    output_list.append(data['O'])\n",
    "    return output_list\n",
    "\n",
    "df['combined_labels'] = df.apply(lambda x: combine_list(x), axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0]    1051\n",
       "[0, 1, 0, 0, 0, 0, 0, 0]     687\n",
       "[0, 0, 0, 0, 0, 0, 0, 1]     440\n",
       "[0, 1, 0, 0, 0, 0, 0, 1]     233\n",
       "[0, 0, 0, 1, 0, 0, 0, 0]     139\n",
       "[0, 0, 0, 0, 1, 0, 0, 0]     117\n",
       "[0, 0, 1, 0, 0, 0, 0, 0]     117\n",
       "[0, 0, 0, 0, 0, 0, 1, 0]     103\n",
       "[0, 1, 0, 0, 0, 1, 0, 0]      44\n",
       "[0, 0, 0, 0, 0, 1, 0, 0]      36\n",
       "[0, 1, 0, 1, 0, 0, 0, 0]      31\n",
       "[0, 0, 1, 0, 0, 0, 0, 1]      30\n",
       "[0, 0, 0, 0, 0, 0, 1, 1]      27\n",
       "[0, 0, 0, 1, 0, 0, 0, 1]      21\n",
       "[0, 1, 1, 0, 0, 0, 0, 0]      20\n",
       "[0, 1, 0, 0, 0, 0, 1, 0]      14\n",
       "[0, 1, 0, 0, 1, 0, 0, 0]      14\n",
       "[0, 0, 0, 0, 1, 0, 0, 1]      12\n",
       "[0, 0, 1, 0, 1, 0, 0, 0]      10\n",
       "[0, 0, 0, 0, 0, 1, 0, 1]       8\n",
       "[0, 1, 0, 1, 0, 0, 0, 1]       6\n",
       "[0, 0, 1, 0, 0, 1, 0, 0]       5\n",
       "[0, 0, 1, 0, 0, 0, 1, 0]       5\n",
       "[0, 1, 1, 0, 0, 0, 0, 1]       5\n",
       "[0, 0, 0, 0, 1, 1, 0, 0]       4\n",
       "[0, 0, 1, 0, 0, 1, 0, 1]       3\n",
       "[0, 1, 0, 0, 0, 0, 1, 1]       3\n",
       "[0, 0, 0, 1, 0, 1, 0, 0]       2\n",
       "[0, 0, 1, 1, 0, 0, 0, 0]       2\n",
       "[0, 1, 0, 0, 1, 0, 0, 1]       1\n",
       "[0, 1, 0, 0, 0, 1, 0, 1]       1\n",
       "[0, 0, 1, 1, 0, 0, 0, 1]       1\n",
       "[0, 1, 0, 0, 1, 0, 1, 0]       1\n",
       "[0, 1, 1, 0, 0, 0, 1, 0]       1\n",
       "Name: combined_labels, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:3194]['combined_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>...</th>\n",
       "      <th>O</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "      <th>pixel_data</th>\n",
       "      <th>y_labels</th>\n",
       "      <th>bin_labels</th>\n",
       "      <th>c_labels</th>\n",
       "      <th>combined_labels</th>\n",
       "      <th>nd_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "\n",
       "  Left-Diagnostic Keywords Right-Diagnostic Keywords  N  D  G  ...  O  labels  \\\n",
       "0                 cataract             normal fundus  0  0  0  ...  0   ['N']   \n",
       "\n",
       "                     target     filename  \\\n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg   \n",
       "\n",
       "                                          pixel_data y_labels bin_labels  \\\n",
       "0  <PIL.JpegImagePlugin.JpegImageFile image mode=...        N          0   \n",
       "\n",
       "  c_labels           combined_labels nd_labels  \n",
       "0        0  [0, 0, 0, 1, 0, 0, 0, 0]         0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create two y labeling methods for different models later on\n",
    "def y_labels(label):\n",
    "    return label[2]\n",
    "\n",
    "def simplify(label):\n",
    "    if label[2] == 'N':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def only_c(label):\n",
    "    if label[2] == 'C':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def n_d(label):\n",
    "    if label[2] == 'D':\n",
    "        return 1\n",
    "    elif label[2] == 'N':\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "df['y_labels'] = df['labels'].apply(lambda x: y_labels(x))\n",
    "df['bin_labels'] = df['labels'].apply(lambda x: simplify(x))\n",
    "df['c_labels'] = df['labels'].apply(lambda x: only_c(x))\n",
    "df['nd_labels'] = df['labels'].apply(lambda x: n_d(x))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2873\n",
       "2    1911\n",
       "1    1608\n",
       "Name: nd_labels, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['c_labels'].value_counts()\n",
    "df['nd_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3519\n",
       "0    2873\n",
       "Name: bin_labels, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the data is balanced enough, seems ok in this case\n",
    "df['bin_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the image data into array \n",
    "for img in range(len(all_images)):\n",
    "    all_images[img] = image.img_to_array(all_images[img])\n",
    "    all_images[img] = all_images[img]/255\n",
    "image_array = np.array(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 128, 128, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in range(len(all_images_left)):\n",
    "    all_images_left[img] = image.img_to_array(all_images_left[img])\n",
    "for img in range(len(all_images_right)):\n",
    "    all_images_right[img] = image.img_to_array(all_images_right[img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array_l = np.array(all_images_left)\n",
    "image_array_r = np.array(all_images_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 128, 128, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3198"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the index number where the left eye image starts\n",
    "y = df['y_labels'][3194:]\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "# x_train = np.array(all_images)\n",
    "# X_unprocessed = df['pixel_data']\n",
    "# transformer = ImageDataGenerator(rescale=3.0/255.)\n",
    "# X = transformer.flow_from_dataframe(df, x_col=X_unprocessed, batch_size=20, target_size=(128,128))\n",
    "# print(X.shape)\n",
    "# print(X[0])\n",
    "\n",
    "y = df['y_labels']\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = utils.to_categorical(encoded_y)\n",
    "\n",
    "binary_y = df['bin_labels']\n",
    "binary_y = utils.to_categorical(binary_y)\n",
    "\n",
    "c_y = df['c_labels']\n",
    "c_y = utils.to_categorical(c_y)\n",
    "\n",
    "nd_y = df['nd_labels']\n",
    "nd_y = utils.to_categorical(nd_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_array, nd_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5113, 128, 128, 3)\n",
      "(5113, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first model\n",
    "using softmax as the last activation function, num_classes should be changed when creating different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(32,(3,3),\n",
    "              activation='relu',\n",
    "              input_shape=(128,128,3)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(32,(3,3),activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(16,(3,3),activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(32, activation='relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(16, activation='relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(num_classes, activation='softmax'))\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best accuracy for binary in this model is 55%, for multi-categories is around 46%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "205/205 [==============================] - 22s 109ms/step - loss: 1.0793 - accuracy: 0.4462 - precision: 0.3396 - recall: 0.0044 - val_loss: 1.0685 - val_accuracy: 0.4604 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/15\n",
      "205/205 [==============================] - 22s 109ms/step - loss: 1.0748 - accuracy: 0.4455 - precision: 0.4000 - recall: 4.8900e-04 - val_loss: 1.0616 - val_accuracy: 0.4604 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/15\n",
      "205/205 [==============================] - 22s 109ms/step - loss: 1.0712 - accuracy: 0.4455 - precision: 0.4691 - recall: 0.0093 - val_loss: 1.0623 - val_accuracy: 0.4604 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/15\n",
      "205/205 [==============================] - 21s 103ms/step - loss: 1.0695 - accuracy: 0.4455 - precision: 0.4074 - recall: 0.0054 - val_loss: 1.0602 - val_accuracy: 0.4604 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/15\n",
      "205/205 [==============================] - 21s 102ms/step - loss: 1.0677 - accuracy: 0.4455 - precision: 0.5000 - recall: 0.0196 - val_loss: 1.0600 - val_accuracy: 0.4604 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/15\n",
      "205/205 [==============================] - 21s 102ms/step - loss: 1.0676 - accuracy: 0.4455 - precision: 0.5254 - recall: 0.0152 - val_loss: 1.0582 - val_accuracy: 0.4604 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/15\n",
      "205/205 [==============================] - 21s 104ms/step - loss: 1.0665 - accuracy: 0.4455 - precision: 0.4763 - recall: 0.0369 - val_loss: 1.0580 - val_accuracy: 0.4604 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/15\n",
      "205/205 [==============================] - 22s 105ms/step - loss: 1.0650 - accuracy: 0.4455 - precision: 0.5119 - recall: 0.0472 - val_loss: 1.0549 - val_accuracy: 0.4604 - val_precision: 0.5247 - val_recall: 0.1144\n",
      "Epoch 9/15\n",
      "205/205 [==============================] - 22s 106ms/step - loss: 1.0644 - accuracy: 0.4455 - precision: 0.5269 - recall: 0.0670 - val_loss: 1.0544 - val_accuracy: 0.4604 - val_precision: 0.5287 - val_recall: 0.0811\n",
      "Epoch 10/15\n",
      "205/205 [==============================] - 22s 107ms/step - loss: 1.0628 - accuracy: 0.4455 - precision: 0.5266 - recall: 0.0702 - val_loss: 1.0559 - val_accuracy: 0.4604 - val_precision: 0.5556 - val_recall: 0.0098\n",
      "Epoch 11/15\n",
      "205/205 [==============================] - 23s 111ms/step - loss: 1.0625 - accuracy: 0.4455 - precision: 0.5426 - recall: 0.0670 - val_loss: 1.0515 - val_accuracy: 0.4604 - val_precision: 0.5368 - val_recall: 0.1427\n",
      "Epoch 12/15\n",
      "205/205 [==============================] - 23s 113ms/step - loss: 1.0625 - accuracy: 0.4452 - precision: 0.5316 - recall: 0.0802 - val_loss: 1.0532 - val_accuracy: 0.4604 - val_precision: 0.5493 - val_recall: 0.0381\n",
      "Epoch 13/15\n",
      "205/205 [==============================] - 23s 113ms/step - loss: 1.0616 - accuracy: 0.4455 - precision: 0.5364 - recall: 0.0631 - val_loss: 1.0521 - val_accuracy: 0.4604 - val_precision: 0.5412 - val_recall: 0.1026\n",
      "Epoch 14/15\n",
      "205/205 [==============================] - 22s 109ms/step - loss: 1.0610 - accuracy: 0.4457 - precision: 0.5120 - recall: 0.0785 - val_loss: 1.0494 - val_accuracy: 0.4604 - val_precision: 0.5564 - val_recall: 0.1447\n",
      "Epoch 15/15\n",
      "205/205 [==============================] - 23s 111ms/step - loss: 1.0584 - accuracy: 0.4455 - precision: 0.5417 - recall: 0.1017 - val_loss: 1.0497 - val_accuracy: 0.4604 - val_precision: 0.5312 - val_recall: 0.0997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fadd851b1f0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=20\n",
    "epochs=15\n",
    "\n",
    "img_rows, img_cols = 28,28\n",
    "\n",
    "\n",
    "cnn.fit(X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "       callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [1. 0.] [0. 1.]\n",
      "41 [1. 0.] [0. 1.]\n",
      "60 [1. 0.] [0. 1.]\n",
      "70 [1. 0.] [0. 1.]\n",
      "91 [1. 0.] [0. 1.]\n",
      "98 [1. 0.] [0. 1.]\n",
      "131 [1. 0.] [0. 1.]\n",
      "132 [1. 0.] [0. 1.]\n",
      "133 [1. 0.] [0. 1.]\n",
      "140 [1. 0.] [0. 1.]\n",
      "162 [1. 0.] [0. 1.]\n",
      "178 [1. 0.] [0. 1.]\n",
      "199 [1. 0.] [0. 1.]\n",
      "224 [1. 0.] [0. 1.]\n",
      "235 [1. 0.] [0. 1.]\n",
      "262 [1. 0.] [0. 1.]\n",
      "267 [1. 0.] [0. 1.]\n",
      "288 [1. 0.] [0. 1.]\n",
      "321 [1. 0.] [0. 1.]\n",
      "330 [1. 0.] [0. 1.]\n",
      "333 [1. 0.] [0. 1.]\n",
      "337 [1. 0.] [0. 1.]\n",
      "365 [1. 0.] [0. 1.]\n",
      "388 [1. 0.] [0. 1.]\n",
      "391 [1. 0.] [0. 1.]\n",
      "416 [1. 0.] [0. 1.]\n",
      "457 [1. 0.] [0. 1.]\n",
      "497 [1. 0.] [0. 1.]\n",
      "562 [1. 0.] [0. 1.]\n",
      "713 [1. 0.] [0. 1.]\n",
      "715 [1. 0.] [0. 1.]\n",
      "722 [1. 0.] [0. 1.]\n",
      "737 [1. 0.] [0. 1.]\n",
      "765 [1. 0.] [0. 1.]\n",
      "780 [1. 0.] [0. 1.]\n",
      "801 [1. 0.] [0. 1.]\n",
      "806 [1. 0.] [0. 1.]\n",
      "813 [1. 0.] [0. 1.]\n",
      "818 [1. 0.] [0. 1.]\n",
      "850 [1. 0.] [0. 1.]\n",
      "864 [1. 0.] [0. 1.]\n",
      "890 [1. 0.] [0. 1.]\n",
      "895 [1. 0.] [0. 1.]\n",
      "909 [1. 0.] [0. 1.]\n",
      "931 [1. 0.] [0. 1.]\n",
      "957 [1. 0.] [0. 1.]\n",
      "973 [1. 0.] [0. 1.]\n",
      "1000 [1. 0.] [0. 1.]\n",
      "1005 [1. 0.] [0. 1.]\n",
      "1014 [1. 0.] [0. 1.]\n",
      "1031 [1. 0.] [0. 1.]\n",
      "1041 [1. 0.] [0. 1.]\n",
      "1087 [1. 0.] [0. 1.]\n",
      "1095 [1. 0.] [0. 1.]\n",
      "1186 [1. 0.] [0. 1.]\n",
      "1195 [1. 0.] [0. 1.]\n",
      "1197 [1. 0.] [0. 1.]\n",
      "1232 [1. 0.] [0. 1.]\n",
      "1275 [1. 0.] [0. 1.]\n",
      "1344 [1. 0.] [0. 1.]\n",
      "1350 [1. 0.] [0. 1.]\n",
      "1357 [1. 0.] [0. 1.]\n",
      "1376 [1. 0.] [0. 1.]\n",
      "1377 [1. 0.] [0. 1.]\n",
      "1378 [1. 0.] [0. 1.]\n",
      "1383 [1. 0.] [0. 1.]\n",
      "1408 [1. 0.] [0. 1.]\n",
      "1421 [1. 0.] [0. 1.]\n",
      "1437 [1. 0.] [0. 1.]\n",
      "1450 [1. 0.] [0. 1.]\n",
      "1457 [1. 0.] [0. 1.]\n",
      "1468 [1. 0.] [0. 1.]\n",
      "1485 [1. 0.] [0. 1.]\n",
      "1507 [1. 0.] [0. 1.]\n",
      "1534 [1. 0.] [0. 1.]\n",
      "1545 [1. 0.] [0. 1.]\n",
      "76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04755944931163955"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in y_predict:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] == max(i):\n",
    "            i[j] = 1\n",
    "        else:\n",
    "            i[j] = 0\n",
    "count=0\n",
    "for i in range(len(y_predict)):\n",
    "    if np.where(y_predict[i] == 1) == 1:\n",
    "        print('ya!')\n",
    "    if np.where(y_predict[i] == 1) != np.where(y_test[i] == 1):\n",
    "        count+=1\n",
    "        print(i, y_predict[i], y_test[i])\n",
    "print(count)\n",
    "count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0540205240249634\n",
      "Test accuracy: 0.45817044377326965\n"
     ]
    }
   ],
   "source": [
    "score = cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# print(6099/(293+6099))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The second model\n",
    "the very first model - using sigmoid as the last activation function, nodes are set to 8 currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(128,128,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "240/240 [==============================] - 25s 103ms/step - loss: 0.1999 - accuracy: 0.9547\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 26s 108ms/step - loss: 0.1778 - accuracy: 0.9547\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 26s 107ms/step - loss: 0.1717 - accuracy: 0.9547\n",
      "Epoch 4/10\n",
      "  7/240 [..............................] - ETA: 21s - loss: 0.1714 - accuracy: 0.9500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-22bfe5e00875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The third model\n",
    "reference - https://www.kaggle.com/roobansappani/cataract-detection\n",
    "saw this notebook and it got 93% of accuracy, so I decided to test on the binary case\n",
    "the model takes a LONG time to fit(check the seconds), I only train for 10 epochs in the following model\n",
    "### got an accuracy of 63%, could possibly get higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "vgg = VGG19(weights = \"imagenet\", include_top = False, input_shape=(128, 128, 3))\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(vgg)\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(64, activation = 'relu'))\n",
    "model_1.add(Dense(2,activation = \"softmax\"))\n",
    "model_1.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "30/30 [==============================] - 186s 6s/step - loss: 0.3046 - accuracy: 0.9259 - precision: 0.9259 - recall: 0.9259 - val_loss: 0.1507 - val_accuracy: 0.9552 - val_precision: 0.9552 - val_recall: 0.9552\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 179s 6s/step - loss: 0.1244 - accuracy: 0.9567 - precision: 0.9567 - recall: 0.9567 - val_loss: 0.1105 - val_accuracy: 0.9541 - val_precision: 0.9541 - val_recall: 0.9541\n",
      "Epoch 3/4\n",
      "30/30 [==============================] - 181s 6s/step - loss: 0.0995 - accuracy: 0.9606 - precision: 0.9606 - recall: 0.9606 - val_loss: 0.0957 - val_accuracy: 0.9593 - val_precision: 0.9593 - val_recall: 0.9593\n",
      "Epoch 4/4\n",
      "30/30 [==============================] - 179s 6s/step - loss: 0.0869 - accuracy: 0.9664 - precision: 0.9664 - recall: 0.9664 - val_loss: 0.0847 - val_accuracy: 0.9625 - val_precision: 0.9625 - val_recall: 0.9625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb0cc77c460>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train, y_train, \n",
    "            validation_split = 0.2, \n",
    "            epochs = 4,\n",
    "            batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08584222197532654\n",
      "Test accuracy: 0.969962477684021\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel('./ODIR-5K/ODIR-5K/data.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>1_left.jpg</td>\n",
       "      <td>1_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>2_left.jpg</td>\n",
       "      <td>2_right.jpg</td>\n",
       "      <td>laser spot，moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>Male</td>\n",
       "      <td>3_left.jpg</td>\n",
       "      <td>3_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>branch retinal artery occlusion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>4686</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>4686_left.jpg</td>\n",
       "      <td>4686_right.jpg</td>\n",
       "      <td>severe nonproliferative retinopathy</td>\n",
       "      <td>proliferative diabetic retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>4688</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>4688_left.jpg</td>\n",
       "      <td>4688_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>4689</td>\n",
       "      <td>54</td>\n",
       "      <td>Male</td>\n",
       "      <td>4689_left.jpg</td>\n",
       "      <td>4689_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>4690</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>4690_left.jpg</td>\n",
       "      <td>4690_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>4784</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>4784_left.jpg</td>\n",
       "      <td>4784_right.jpg</td>\n",
       "      <td>hypertensive retinopathy，age-related macular d...</td>\n",
       "      <td>hypertensive retinopathy，age-related macular d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Patient Age Patient Sex    Left-Fundus    Right-Fundus  \\\n",
       "0        0           69      Female     0_left.jpg     0_right.jpg   \n",
       "1        1           57        Male     1_left.jpg     1_right.jpg   \n",
       "2        2           42        Male     2_left.jpg     2_right.jpg   \n",
       "3        3           66        Male     3_left.jpg     3_right.jpg   \n",
       "4        4           53        Male     4_left.jpg     4_right.jpg   \n",
       "...    ...          ...         ...            ...             ...   \n",
       "3495  4686           63        Male  4686_left.jpg  4686_right.jpg   \n",
       "3496  4688           42        Male  4688_left.jpg  4688_right.jpg   \n",
       "3497  4689           54        Male  4689_left.jpg  4689_right.jpg   \n",
       "3498  4690           57        Male  4690_left.jpg  4690_right.jpg   \n",
       "3499  4784           58        Male  4784_left.jpg  4784_right.jpg   \n",
       "\n",
       "                               Left-Diagnostic Keywords  \\\n",
       "0                                              cataract   \n",
       "1                                         normal fundus   \n",
       "2     laser spot，moderate non proliferative retinopathy   \n",
       "3                                         normal fundus   \n",
       "4                           macular epiretinal membrane   \n",
       "...                                                 ...   \n",
       "3495                severe nonproliferative retinopathy   \n",
       "3496             moderate non proliferative retinopathy   \n",
       "3497                  mild nonproliferative retinopathy   \n",
       "3498                  mild nonproliferative retinopathy   \n",
       "3499  hypertensive retinopathy，age-related macular d...   \n",
       "\n",
       "                              Right-Diagnostic Keywords  N  D  G  C  A  H  M  \\\n",
       "0                                         normal fundus  0  0  0  1  0  0  0   \n",
       "1                                         normal fundus  1  0  0  0  0  0  0   \n",
       "2                moderate non proliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3                       branch retinal artery occlusion  0  0  0  0  0  0  0   \n",
       "4                     mild nonproliferative retinopathy  0  1  0  0  0  0  0   \n",
       "...                                                 ... .. .. .. .. .. .. ..   \n",
       "3495                 proliferative diabetic retinopathy  0  1  0  0  0  0  0   \n",
       "3496             moderate non proliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3497                                      normal fundus  0  1  0  0  0  0  0   \n",
       "3498                  mild nonproliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3499  hypertensive retinopathy，age-related macular d...  0  0  0  0  1  1  0   \n",
       "\n",
       "      O  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  \n",
       "...  ..  \n",
       "3495  0  \n",
       "3496  0  \n",
       "3497  0  \n",
       "3498  0  \n",
       "3499  0  \n",
       "\n",
       "[3500 rows x 15 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3519, 100, 100, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allim = []\n",
    "for i in range(len(df[df['labels'] != \"['N']\"]['filename'])):\n",
    "    img = image.load_img('./preprocessed_images/'+df[df['labels'] != \"['N']\"]['filename'].iloc[i],target_size=(100,100))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    allim.append(img)\n",
    "image_array2 = np.array(allim)\n",
    "image_array2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2_right.jpg'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['labels'] != \"['N']\"]['filename'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       D\n",
       "3       D\n",
       "4       D\n",
       "5       D\n",
       "6       D\n",
       "       ..\n",
       "6387    D\n",
       "6388    D\n",
       "6389    D\n",
       "6390    D\n",
       "6391    H\n",
       "Name: y_labels, Length: 3519, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_n_y = df[df['labels'] != \"['N']\"]['y_labels']\n",
    "no_n_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_n_y = df[df['labels'] != \"['N']\"]['y_labels']\n",
    "encoder2 = LabelEncoder()\n",
    "encoder.fit(no_n_y)\n",
    "encoded_no_n_y = encoder.transform(no_n_y)\n",
    "dummy_no_n_y = utils.to_categorical(encoded_no_n_y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_array2, dummy_no_n_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    1608\n",
       "O     708\n",
       "C     293\n",
       "G     284\n",
       "A     266\n",
       "M     232\n",
       "H     128\n",
       "Name: y_labels, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['labels'] != \"['N']\"]['y_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2815, 100, 100, 3)\n",
      "(2815, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "cnn2 = Sequential()\n",
    "cnn2.add(Conv2D(50,(3,3),\n",
    "              activation='relu',\n",
    "              input_shape=(100,100,3)))\n",
    "cnn2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn2.add(Conv2D(25,(3,3),activation='relu'))\n",
    "cnn2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn2.add(Conv2D(16,(3,3),activation='relu'))\n",
    "cnn2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn2.add(Flatten())\n",
    "cnn2.add(Dense(128, activation='relu'))\n",
    "cnn2.add(Dropout(0.3))\n",
    "cnn2.add(Dense(64, activation='relu'))\n",
    "cnn2.add(Dropout(0.3))\n",
    "cnn2.add(Dense(num_classes, activation='softmax'))\n",
    "cnn2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "113/113 [==============================] - 12s 102ms/step - loss: 1.6902 - accuracy: 0.4405 - precision: 0.4875 - recall: 0.0782 - val_loss: 1.5647 - val_accuracy: 0.4938 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/15\n",
      "113/113 [==============================] - 11s 99ms/step - loss: 1.6253 - accuracy: 0.4525 - precision: 0.4667 - recall: 0.1026 - val_loss: 1.5451 - val_accuracy: 0.4938 - val_precision: 0.3500 - val_recall: 0.0124\n",
      "Epoch 3/15\n",
      "113/113 [==============================] - 11s 99ms/step - loss: 1.6150 - accuracy: 0.4503 - precision: 0.5214 - recall: 0.1137 - val_loss: 1.5318 - val_accuracy: 0.4938 - val_precision: 0.5106 - val_recall: 0.0426\n",
      "Epoch 4/15\n",
      "113/113 [==============================] - 11s 101ms/step - loss: 1.6118 - accuracy: 0.4525 - precision: 0.4627 - recall: 0.0937 - val_loss: 1.5447 - val_accuracy: 0.4938 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/15\n",
      "113/113 [==============================] - 12s 102ms/step - loss: 1.6024 - accuracy: 0.4520 - precision: 0.4650 - recall: 0.0972 - val_loss: 1.5489 - val_accuracy: 0.4938 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/15\n",
      "113/113 [==============================] - 11s 101ms/step - loss: 1.5902 - accuracy: 0.4529 - precision: 0.4881 - recall: 0.1097 - val_loss: 1.5378 - val_accuracy: 0.4938 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/15\n",
      "113/113 [==============================] - 12s 103ms/step - loss: 1.5939 - accuracy: 0.4525 - precision: 0.4872 - recall: 0.0928 - val_loss: 1.5149 - val_accuracy: 0.4938 - val_precision: 0.5127 - val_recall: 0.1794\n",
      "Epoch 8/15\n",
      "113/113 [==============================] - 11s 100ms/step - loss: 1.5760 - accuracy: 0.4529 - precision: 0.5081 - recall: 0.1261 - val_loss: 1.5225 - val_accuracy: 0.4938 - val_precision: 0.5000 - val_recall: 0.0036\n",
      "Epoch 9/15\n",
      "113/113 [==============================] - 11s 102ms/step - loss: 1.5768 - accuracy: 0.4529 - precision: 0.5051 - recall: 0.1106 - val_loss: 1.5042 - val_accuracy: 0.4938 - val_precision: 0.5337 - val_recall: 0.3375\n",
      "Epoch 10/15\n",
      "113/113 [==============================] - 12s 103ms/step - loss: 1.5671 - accuracy: 0.4529 - precision: 0.4885 - recall: 0.1132 - val_loss: 1.4904 - val_accuracy: 0.4938 - val_precision: 0.5309 - val_recall: 0.2291\n",
      "Epoch 11/15\n",
      "113/113 [==============================] - 12s 103ms/step - loss: 1.5587 - accuracy: 0.4529 - precision: 0.5059 - recall: 0.1137 - val_loss: 1.4890 - val_accuracy: 0.4938 - val_precision: 0.5383 - val_recall: 0.3748\n",
      "Epoch 12/15\n",
      "113/113 [==============================] - 12s 102ms/step - loss: 1.5458 - accuracy: 0.4543 - precision: 0.4966 - recall: 0.1292 - val_loss: 1.4753 - val_accuracy: 0.4938 - val_precision: 0.5758 - val_recall: 0.1012\n",
      "Epoch 13/15\n",
      "113/113 [==============================] - 12s 102ms/step - loss: 1.5379 - accuracy: 0.4538 - precision: 0.5229 - recall: 0.1266 - val_loss: 1.4659 - val_accuracy: 0.4938 - val_precision: 0.5672 - val_recall: 0.2025\n",
      "Epoch 14/15\n",
      "113/113 [==============================] - 12s 104ms/step - loss: 1.5109 - accuracy: 0.4583 - precision: 0.5426 - recall: 0.1612 - val_loss: 1.4405 - val_accuracy: 0.4956 - val_precision: 0.5743 - val_recall: 0.2060\n",
      "Epoch 15/15\n",
      "113/113 [==============================] - 11s 102ms/step - loss: 1.4982 - accuracy: 0.4614 - precision: 0.5199 - recall: 0.1505 - val_loss: 1.4350 - val_accuracy: 0.4938 - val_precision: 0.5771 - val_recall: 0.2060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fae5d74fe50>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=20\n",
    "epochs=15\n",
    "\n",
    "img_rows, img_cols = 28,28\n",
    "\n",
    "\n",
    "cnn2.fit(X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "       callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43892045454545453"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = cnn2.predict(X_test)\n",
    "for i in y_predict:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] == max(i):\n",
    "            i[j] = 1\n",
    "        else:\n",
    "            i[j] = 0\n",
    "count=0\n",
    "for i in range(len(y_predict)):\n",
    "    if np.where(y_predict[i] == 1) == np.where(y_test[i] == 1):\n",
    "        count+=1\n",
    "count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.555878758430481\n",
      "Test accuracy: 0.4389204680919647\n"
     ]
    }
   ],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "vgg = VGG19(weights = \"imagenet\", include_top = False, input_shape=(100, 100, 3))\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(vgg)\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(64, activation = 'relu'))\n",
    "model_1.add(Dense(7,activation = \"softmax\"))\n",
    "model_1.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(X_train, y_train, \n",
    "            validation_split = 0.2, \n",
    "            epochs = 4,\n",
    "            batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
