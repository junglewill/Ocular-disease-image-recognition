{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>filepath</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_right.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "\n",
       "  Left-Diagnostic Keywords Right-Diagnostic Keywords  N  D  G  C  A  H  M  O  \\\n",
       "0                 cataract             normal fundus  0  0  0  1  0  0  0  0   \n",
       "\n",
       "                                            filepath labels  \\\n",
       "0  ../input/ocular-disease-recognition-odir5k/ODI...  ['N']   \n",
       "\n",
       "                     target     filename  \n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['filename'] == '0_right.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>filepath</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['D']</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['O']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>4_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "3      4           53        Male  4_left.jpg  4_right.jpg   \n",
       "3197   4           53        Male  4_left.jpg  4_right.jpg   \n",
       "\n",
       "         Left-Diagnostic Keywords          Right-Diagnostic Keywords  N  D  G  \\\n",
       "3     macular epiretinal membrane  mild nonproliferative retinopathy  0  1  0   \n",
       "3197  macular epiretinal membrane  mild nonproliferative retinopathy  0  1  0   \n",
       "\n",
       "      C  A  H  M  O                                           filepath labels  \\\n",
       "3     0  0  0  0  1  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
       "3197  0  0  0  0  1  ../input/ocular-disease-recognition-odir5k/ODI...  ['O']   \n",
       "\n",
       "                        target     filename  \n",
       "3     [0, 1, 0, 0, 0, 0, 0, 0]  4_right.jpg  \n",
       "3197  [0, 0, 0, 0, 0, 0, 0, 1]   4_left.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is to show that the dataset separate two image files in two rows\n",
    "df[df['Left-Fundus'] == '4_left.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the string slicing \n",
    "x = df['filename']\n",
    "name = x[0][:-4]\n",
    "name[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test imputing the image\n",
    "# y = df['filename'][0]\n",
    "# im = Image.open(f'./0_right_thumbnail.jpg')\n",
    "# list(im.getdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./preprocessed_images/{x}', 'r') as f:\n",
    "#     print(f)\n",
    "\n",
    "# The following grabs all the images from the preprocessed_images folder, and create thumbnail to reduce the data size \n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# create three lists(all, left, right) for the model later\n",
    "all_images = []\n",
    "all_images_left = []\n",
    "all_images_right = []\n",
    "def get_pixels(values):\n",
    "    im = Image.open(f'./preprocessed_images/{values}')\n",
    "    name = values[:-4]\n",
    "    im.thumbnail((128,128))\n",
    "    all_images.append(im)\n",
    "    if name[-5] == 'r':\n",
    "        all_images_right.append(im)\n",
    "    else:\n",
    "        all_images_left.append(im)\n",
    "    return im\n",
    "\n",
    "df['pixel_data'] = df['filename'].apply(lambda x: get_pixels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffdfd147a60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# countplot to show the distribution of the dataset\n",
    "import seaborn as sns\n",
    "sns.countplot(df['y_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    2873\n",
       "D    1608\n",
       "O     708\n",
       "C     293\n",
       "G     284\n",
       "A     266\n",
       "M     232\n",
       "H     128\n",
       "Name: y_labels, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('filepath', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>...</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "      <th>pixel_data</th>\n",
       "      <th>y_labels</th>\n",
       "      <th>bin_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "\n",
       "  Left-Diagnostic Keywords Right-Diagnostic Keywords  N  D  G  ...  A  H  M  \\\n",
       "0                 cataract             normal fundus  0  0  0  ...  0  0  0   \n",
       "\n",
       "   O  labels                    target     filename  \\\n",
       "0  0   ['N']  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg   \n",
       "\n",
       "                                          pixel_data y_labels bin_labels  \n",
       "0  <PIL.JpegImagePlugin.JpegImageFile image mode=...        N          0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create two y labeling methods for different models later on\n",
    "def y_labels(label):\n",
    "    return label[2]\n",
    "\n",
    "def simplify(label):\n",
    "    if label[2] == 'N':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def without_n(label):\n",
    "    \n",
    "    \n",
    "df['y_labels'] = df['labels'].apply(lambda x: y_labels(x))\n",
    "df['bin_labels'] = df['labels'].apply(lambda x: simplify(x))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3519\n",
       "0    2873\n",
       "Name: bin_labels, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the data is balanced enough, seems ok in this case\n",
    "df['bin_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the image data into array \n",
    "for img in range(len(all_images)):\n",
    "    all_images[img] = image.img_to_array(all_images[img])\n",
    "    all_images[img] = all_images[img]/255\n",
    "image_array = np.array(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 128, 128, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in range(len(all_images_left)):\n",
    "    all_images_left[img] = image.img_to_array(all_images_left[img])\n",
    "for img in range(len(all_images_right)):\n",
    "    all_images_right[img] = image.img_to_array(all_images_right[img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array_l = np.array(all_images_left)\n",
    "image_array_r = np.array(all_images_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 128, 128, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 100, 100, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allim = []\n",
    "for i in range(len(df['filename'])):\n",
    "    img = image.load_img('./preprocessed_images/'+df['filename'][i],target_size=(100,100))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    allim.append(img)\n",
    "image_array2 = np.array(allim)\n",
    "image_array2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3198"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the index number where the left eye image starts\n",
    "y = df['y_labels'][3194:]\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "# x_train = np.array(all_images)\n",
    "# X_unprocessed = df['pixel_data']\n",
    "# transformer = ImageDataGenerator(rescale=3.0/255.)\n",
    "# X = transformer.flow_from_dataframe(df, x_col=X_unprocessed, batch_size=20, target_size=(128,128))\n",
    "# print(X.shape)\n",
    "# print(X[0])\n",
    "\n",
    "y = df['y_labels']\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = utils.to_categorical(encoded_y)\n",
    "\n",
    "binary_y = df['bin_labels']\n",
    "binary_y = utils.to_categorical(binary_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_array, dummy_y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4794, 128, 128, 3)\n",
      "(4794, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first model\n",
    "using softmax as the last activation function, num_classes should be changed when creating different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 126, 126, 25)      700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 63, 63, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 61, 61, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 30, 30, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 45000)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               5760128   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 5,780,904\n",
      "Trainable params: 5,780,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "num_classes = 8\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(25,(3,3),\n",
    "              activation='relu',\n",
    "              input_shape=(128,128,3)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(50,(3,3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(num_classes, activation='softmax'))\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import pydotplus\n",
    "import pydot\n",
    "\n",
    "plot_model(cnn, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best accuracy for binary in this model is 55%, for multi-categories is around 46%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 1.6782 - accuracy: 0.4141 - precision: 0.4245 - recall: 0.0777 - val_loss: 1.5767 - val_accuracy: 0.4421 - val_precision: 0.3333 - val_recall: 0.0010\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 1.6023 - accuracy: 0.4415 - precision: 0.4810 - recall: 0.1022 - val_loss: 1.5541 - val_accuracy: 0.4421 - val_precision: 0.6111 - val_recall: 0.0115\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 1.5654 - accuracy: 0.4469 - precision: 0.4911 - recall: 0.1153 - val_loss: 1.5427 - val_accuracy: 0.4432 - val_precision: 0.5714 - val_recall: 0.1210\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 1.5557 - accuracy: 0.4475 - precision: 0.4862 - recall: 0.1153 - val_loss: 1.5392 - val_accuracy: 0.4421 - val_precision: 0.6667 - val_recall: 0.0292\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 1.5315 - accuracy: 0.4469 - precision: 0.5044 - recall: 0.1184 - val_loss: 1.5156 - val_accuracy: 0.4421 - val_precision: 0.5259 - val_recall: 0.1908\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 1.5167 - accuracy: 0.4545 - precision: 0.5163 - recall: 0.1278 - val_loss: 1.5259 - val_accuracy: 0.4421 - val_precision: 0.6061 - val_recall: 0.0417\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 1.5164 - accuracy: 0.4485 - precision: 0.5055 - recall: 0.1189 - val_loss: 1.5042 - val_accuracy: 0.4453 - val_precision: 0.5727 - val_recall: 0.1314\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 1.4927 - accuracy: 0.4571 - precision: 0.5293 - recall: 0.1319 - val_loss: 1.4721 - val_accuracy: 0.4567 - val_precision: 0.6209 - val_recall: 0.1178\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 1.4834 - accuracy: 0.4574 - precision: 0.5304 - recall: 0.1432 - val_loss: 1.4417 - val_accuracy: 0.4463 - val_precision: 0.7143 - val_recall: 0.0626\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 21s 168ms/step - loss: 1.4511 - accuracy: 0.4600 - precision: 0.5465 - recall: 0.1518 - val_loss: 1.4592 - val_accuracy: 0.4630 - val_precision: 0.5905 - val_recall: 0.1293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffbaddeaa30>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=30\n",
    "epochs=10\n",
    "\n",
    "img_rows, img_cols = 28,28\n",
    "\n",
    "\n",
    "cnn.fit(X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "       callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02430115, 0.05786459, 0.10312879, 0.21184193, 0.00414914,\n",
       "        0.02084046, 0.5095545 , 0.06831941],\n",
       "       [0.05840404, 0.04123365, 0.30181882, 0.03079767, 0.03055104,\n",
       "        0.01725152, 0.3846001 , 0.13534324],\n",
       "       [0.03921281, 0.03033204, 0.29216266, 0.03264115, 0.02628312,\n",
       "        0.01829009, 0.44780064, 0.11327754],\n",
       "       [0.04805551, 0.04086681, 0.29338983, 0.02723557, 0.02724729,\n",
       "        0.01001365, 0.42329398, 0.12989745],\n",
       "       [0.04961231, 0.04542085, 0.26962328, 0.0329733 , 0.02971705,\n",
       "        0.01101359, 0.43583518, 0.12580438]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = cnn.predict(X_test)\n",
    "y_predict[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-89-6dd94b610d60>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = cnn.predict_classes(X_test)\n",
    "y_predict[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = np.argmax(cnn.predict(X_test), axis=-1)\n",
    "y_predict[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13141426783479349"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in y_predict:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] >= 0.5:\n",
    "            i[j] = 1\n",
    "        else:\n",
    "            i[j] = 0\n",
    "count=0\n",
    "for i in range(len(y_predict)):\n",
    "    flag=True\n",
    "    for j in range(8):\n",
    "        if y_predict[i][j] == y_test[i][j]:\n",
    "            continue\n",
    "        else:\n",
    "            flag=False\n",
    "            break\n",
    "    if flag:\n",
    "        count+=1\n",
    "    \n",
    "count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16020025031289112"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in y_predict:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] == max(i):\n",
    "            i[j] = 1\n",
    "        else:\n",
    "            i[j] = 0\n",
    "count=0\n",
    "for i in range(len(y_predict)):\n",
    "    if np.where(y_predict[i] == 1) == np.where(y_test[i] == 1):\n",
    "        count+=1\n",
    "count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4560832791151594 0.9831697054698457 0.15577777777777777\n"
     ]
    }
   ],
   "source": [
    "# calculate only for normal eye\n",
    "y_predict = np.argmax(cnn.predict(X_test), axis=-1)\n",
    "y_test_arg = np.argmax(y_test, axis=-1)\n",
    "\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == 6:\n",
    "        if y_test_arg[i] == 6:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    else:\n",
    "        if y_test_arg[i] == 6:\n",
    "            fn+=1\n",
    "        else:\n",
    "            tn+=1\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f = precision*recall/((precision+recall)*2)\n",
    "print(precision, recall, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4555885791778564\n",
      "Test accuracy: 0.4612014889717102\n"
     ]
    }
   ],
   "source": [
    "score = cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The second model\n",
    "the very first model - using sigmoid as the last activation function, nodes are set to 8 currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 126, 126, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 254016)            0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                16257088  \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 16,263,560\n",
      "Trainable params: 16,263,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(128,128,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, CategoricalAccuracy\n",
    "bin_accu = BinaryAccuracy(dtype=None, threshold=0.5)\n",
    "cat_accu = CategoricalAccuracy()\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "48/48 [==============================] - 24s 493ms/step - loss: 1.6694 - accuracy: 0.4332\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 23s 481ms/step - loss: 1.5862 - accuracy: 0.4506\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 23s 478ms/step - loss: 1.5727 - accuracy: 0.4506\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 23s 481ms/step - loss: 1.5612 - accuracy: 0.4506\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 24s 495ms/step - loss: 1.5513 - accuracy: 0.4506\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 24s 510ms/step - loss: 1.5451 - accuracy: 0.4506\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 26s 551ms/step - loss: 1.5350 - accuracy: 0.4506\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 24s 492ms/step - loss: 1.5313 - accuracy: 0.4506\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 24s 491ms/step - loss: 1.5211 - accuracy: 0.4506\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 24s 497ms/step - loss: 1.5171 - accuracy: 0.4506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffadf334e80>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08385481852315395"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "for i in y_predict:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] >= 0.5:\n",
    "            i[j] = 1\n",
    "        else:\n",
    "            i[j] = 0\n",
    "count=0\n",
    "for i in range(len(y_predict)):\n",
    "    flag=True\n",
    "    for j in range(8):\n",
    "        if y_predict[i][j] == y_test[i][j]:\n",
    "            continue\n",
    "        else:\n",
    "            flag=False\n",
    "            break\n",
    "    if flag:\n",
    "        count+=1\n",
    "    \n",
    "count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44618272841051315"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_arg = np.argmax(y_test, axis=-1)\n",
    "\n",
    "count=0\n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == y_test_arg[i]:\n",
    "        count+=1\n",
    "count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44618272841051315 1.0 0.15426222414539162\n"
     ]
    }
   ],
   "source": [
    "# calculate only for normal eye\n",
    "y_predict = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_arg = np.argmax(y_test, axis=-1)\n",
    "\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == 6:\n",
    "        if y_test_arg[i] == 6:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    else:\n",
    "        if y_test_arg[i] == 6:\n",
    "            fn+=1\n",
    "        else:\n",
    "            tn+=1\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f = precision*recall/((precision+recall)*2)\n",
    "print(precision, recall, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.532153844833374\n",
      "Test accuracy: 0.4461827278137207\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The third model\n",
    "reference - https://www.kaggle.com/roobansappani/cataract-detection\n",
    "saw this notebook and it got 93% of accuracy, so I decided to test on the binary case\n",
    "the model takes a LONG time to fit(check the seconds), I only train for 10 epochs in the following model\n",
    "### got an accuracy of 63%, could possibly get higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "vgg = VGG19(weights = \"imagenet\", include_top = False, input_shape=(128, 128, 3))\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(vgg)\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(64, activation = 'relu'))\n",
    "model_1.add(Dense(2,activation = \"softmax\"))\n",
    "model_1.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 176s 6s/step - loss: 0.6892 - accuracy: 0.5437 - precision: 0.5437 - recall: 0.5437 - val_loss: 0.6793 - val_accuracy: 0.5902 - val_precision: 0.5902 - val_recall: 0.5902\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 176s 6s/step - loss: 0.6716 - accuracy: 0.5739 - precision: 0.5739 - recall: 0.5739 - val_loss: 0.6759 - val_accuracy: 0.5673 - val_precision: 0.5673 - val_recall: 0.5673\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 177s 6s/step - loss: 0.6739 - accuracy: 0.5718 - precision: 0.5718 - recall: 0.5718 - val_loss: 0.6813 - val_accuracy: 0.5485 - val_precision: 0.5485 - val_recall: 0.5485\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 177s 6s/step - loss: 0.6578 - accuracy: 0.5911 - precision: 0.5911 - recall: 0.5911 - val_loss: 0.6924 - val_accuracy: 0.5652 - val_precision: 0.5652 - val_recall: 0.5652\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 176s 6s/step - loss: 0.6514 - accuracy: 0.5958 - precision: 0.5958 - recall: 0.5958 - val_loss: 0.6774 - val_accuracy: 0.5589 - val_precision: 0.5589 - val_recall: 0.5589\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 175s 6s/step - loss: 0.6453 - accuracy: 0.6110 - precision: 0.6110 - recall: 0.6110 - val_loss: 0.6647 - val_accuracy: 0.5871 - val_precision: 0.5871 - val_recall: 0.5871\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 175s 6s/step - loss: 0.6365 - accuracy: 0.6229 - precision: 0.6229 - recall: 0.6229 - val_loss: 0.6642 - val_accuracy: 0.5954 - val_precision: 0.5954 - val_recall: 0.5954\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 175s 6s/step - loss: 0.6361 - accuracy: 0.6211 - precision: 0.6211 - recall: 0.6211 - val_loss: 0.6720 - val_accuracy: 0.5798 - val_precision: 0.5798 - val_recall: 0.5798\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 177s 6s/step - loss: 0.6361 - accuracy: 0.6162 - precision: 0.6162 - recall: 0.6162 - val_loss: 0.6642 - val_accuracy: 0.5808 - val_precision: 0.5808 - val_recall: 0.5808\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 174s 6s/step - loss: 0.6262 - accuracy: 0.6329 - precision: 0.6329 - recall: 0.6329 - val_loss: 0.6702 - val_accuracy: 0.5839 - val_precision: 0.5839 - val_recall: 0.5839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff5f9fd2070>"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train, y_train, \n",
    "            validation_split = 0.2, \n",
    "            epochs = 10,\n",
    "            batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The try model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "num_classes = 8\n",
    "\n",
    "cnn2 = Sequential()\n",
    "cnn2.add(Conv2D(25,(3,3),\n",
    "              activation='relu',\n",
    "              input_shape=(100,100,3)))\n",
    "cnn2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn2.add(Conv2D(50,(3,3), activation='relu'))\n",
    "cnn2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn2.add(Flatten())\n",
    "cnn2.add(Dense(128, activation='relu'))\n",
    "cnn2.add(Dropout(0.3))\n",
    "cnn2.add(Dense(64, activation='relu'))\n",
    "cnn2.add(Dropout(0.3))\n",
    "cnn2.add(Dense(num_classes, activation='softmax'))\n",
    "cnn2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 1.6391 - accuracy: 0.4360 - precision: 0.4606 - recall: 0.0975 - val_loss: 1.5869 - val_accuracy: 0.4432 - val_precision: 0.3750 - val_recall: 0.0031\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 14s 107ms/step - loss: 1.5741 - accuracy: 0.4506 - precision: 0.4883 - recall: 0.1199 - val_loss: 1.5452 - val_accuracy: 0.4432 - val_precision: 0.6000 - val_recall: 0.0282\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 13s 103ms/step - loss: 1.5523 - accuracy: 0.4579 - precision: 0.4900 - recall: 0.1150 - val_loss: 1.5254 - val_accuracy: 0.4463 - val_precision: 0.6618 - val_recall: 0.0469\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 1.5355 - accuracy: 0.4540 - precision: 0.5167 - recall: 0.1452 - val_loss: 1.5162 - val_accuracy: 0.4463 - val_precision: 0.6809 - val_recall: 0.0334\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 14s 106ms/step - loss: 1.5094 - accuracy: 0.4553 - precision: 0.5051 - recall: 0.1291 - val_loss: 1.5143 - val_accuracy: 0.4463 - val_precision: 0.5882 - val_recall: 0.0626\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 14s 111ms/step - loss: 1.4983 - accuracy: 0.4532 - precision: 0.5147 - recall: 0.1327 - val_loss: 1.4915 - val_accuracy: 0.4463 - val_precision: 0.6019 - val_recall: 0.0647\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 1.4785 - accuracy: 0.4584 - precision: 0.5255 - recall: 0.1450 - val_loss: 1.4800 - val_accuracy: 0.4515 - val_precision: 0.5134 - val_recall: 0.3003\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 1.4675 - accuracy: 0.4628 - precision: 0.5170 - recall: 0.1465 - val_loss: 1.4537 - val_accuracy: 0.4505 - val_precision: 0.6619 - val_recall: 0.0959\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 14s 112ms/step - loss: 1.4344 - accuracy: 0.4644 - precision: 0.5453 - recall: 0.1679 - val_loss: 1.5156 - val_accuracy: 0.4599 - val_precision: 0.5137 - val_recall: 0.2742\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 13s 104ms/step - loss: 1.4318 - accuracy: 0.4668 - precision: 0.5595 - recall: 0.1619 - val_loss: 1.4367 - val_accuracy: 0.4578 - val_precision: 0.6433 - val_recall: 0.1053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffbec5ef520>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=30\n",
    "epochs=10\n",
    "\n",
    "img_rows, img_cols = 28,28\n",
    "\n",
    "\n",
    "cnn2.fit(X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "       callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4350862503051758\n",
      "Test accuracy: 0.4524405598640442\n"
     ]
    }
   ],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel('./ODIR-5K/ODIR-5K/data.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>1_left.jpg</td>\n",
       "      <td>1_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>2_left.jpg</td>\n",
       "      <td>2_right.jpg</td>\n",
       "      <td>laser spot，moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>Male</td>\n",
       "      <td>3_left.jpg</td>\n",
       "      <td>3_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>branch retinal artery occlusion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>4686</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>4686_left.jpg</td>\n",
       "      <td>4686_right.jpg</td>\n",
       "      <td>severe nonproliferative retinopathy</td>\n",
       "      <td>proliferative diabetic retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>4688</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>4688_left.jpg</td>\n",
       "      <td>4688_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>4689</td>\n",
       "      <td>54</td>\n",
       "      <td>Male</td>\n",
       "      <td>4689_left.jpg</td>\n",
       "      <td>4689_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>4690</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>4690_left.jpg</td>\n",
       "      <td>4690_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>4784</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>4784_left.jpg</td>\n",
       "      <td>4784_right.jpg</td>\n",
       "      <td>hypertensive retinopathy，age-related macular d...</td>\n",
       "      <td>hypertensive retinopathy，age-related macular d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Patient Age Patient Sex    Left-Fundus    Right-Fundus  \\\n",
       "0        0           69      Female     0_left.jpg     0_right.jpg   \n",
       "1        1           57        Male     1_left.jpg     1_right.jpg   \n",
       "2        2           42        Male     2_left.jpg     2_right.jpg   \n",
       "3        3           66        Male     3_left.jpg     3_right.jpg   \n",
       "4        4           53        Male     4_left.jpg     4_right.jpg   \n",
       "...    ...          ...         ...            ...             ...   \n",
       "3495  4686           63        Male  4686_left.jpg  4686_right.jpg   \n",
       "3496  4688           42        Male  4688_left.jpg  4688_right.jpg   \n",
       "3497  4689           54        Male  4689_left.jpg  4689_right.jpg   \n",
       "3498  4690           57        Male  4690_left.jpg  4690_right.jpg   \n",
       "3499  4784           58        Male  4784_left.jpg  4784_right.jpg   \n",
       "\n",
       "                               Left-Diagnostic Keywords  \\\n",
       "0                                              cataract   \n",
       "1                                         normal fundus   \n",
       "2     laser spot，moderate non proliferative retinopathy   \n",
       "3                                         normal fundus   \n",
       "4                           macular epiretinal membrane   \n",
       "...                                                 ...   \n",
       "3495                severe nonproliferative retinopathy   \n",
       "3496             moderate non proliferative retinopathy   \n",
       "3497                  mild nonproliferative retinopathy   \n",
       "3498                  mild nonproliferative retinopathy   \n",
       "3499  hypertensive retinopathy，age-related macular d...   \n",
       "\n",
       "                              Right-Diagnostic Keywords  N  D  G  C  A  H  M  \\\n",
       "0                                         normal fundus  0  0  0  1  0  0  0   \n",
       "1                                         normal fundus  1  0  0  0  0  0  0   \n",
       "2                moderate non proliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3                       branch retinal artery occlusion  0  0  0  0  0  0  0   \n",
       "4                     mild nonproliferative retinopathy  0  1  0  0  0  0  0   \n",
       "...                                                 ... .. .. .. .. .. .. ..   \n",
       "3495                 proliferative diabetic retinopathy  0  1  0  0  0  0  0   \n",
       "3496             moderate non proliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3497                                      normal fundus  0  1  0  0  0  0  0   \n",
       "3498                  mild nonproliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3499  hypertensive retinopathy，age-related macular d...  0  0  0  0  1  1  0   \n",
       "\n",
       "      O  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  \n",
       "...  ..  \n",
       "3495  0  \n",
       "3496  0  \n",
       "3497  0  \n",
       "3498  0  \n",
       "3499  0  \n",
       "\n",
       "[3500 rows x 15 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
