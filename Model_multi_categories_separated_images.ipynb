{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>filepath</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_right.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "\n",
       "  Left-Diagnostic Keywords Right-Diagnostic Keywords  N  D  G  C  A  H  M  O  \\\n",
       "0                 cataract             normal fundus  0  0  0  1  0  0  0  0   \n",
       "\n",
       "                                            filepath labels  \\\n",
       "0  ../input/ocular-disease-recognition-odir5k/ODI...  ['N']   \n",
       "\n",
       "                     target     filename  \n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['filename'] == '0_right.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>filepath</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['D']</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['O']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>4_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "3      4           53        Male  4_left.jpg  4_right.jpg   \n",
       "3197   4           53        Male  4_left.jpg  4_right.jpg   \n",
       "\n",
       "         Left-Diagnostic Keywords          Right-Diagnostic Keywords  N  D  G  \\\n",
       "3     macular epiretinal membrane  mild nonproliferative retinopathy  0  1  0   \n",
       "3197  macular epiretinal membrane  mild nonproliferative retinopathy  0  1  0   \n",
       "\n",
       "      C  A  H  M  O                                           filepath labels  \\\n",
       "3     0  0  0  0  1  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
       "3197  0  0  0  0  1  ../input/ocular-disease-recognition-odir5k/ODI...  ['O']   \n",
       "\n",
       "                        target     filename  \n",
       "3     [0, 1, 0, 0, 0, 0, 0, 0]  4_right.jpg  \n",
       "3197  [0, 0, 0, 0, 0, 0, 0, 1]   4_left.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is to show that the dataset separate two image files in two rows\n",
    "df[df['Left-Fundus'] == '4_left.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the string slicing \n",
    "x = df['filename']\n",
    "name = x[0][:-4]\n",
    "name[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test imputing the image\n",
    "# y = df['filename'][0]\n",
    "# im = Image.open(f'./0_right_thumbnail.jpg')\n",
    "# list(im.getdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./preprocessed_images/{x}', 'r') as f:\n",
    "#     print(f)\n",
    "\n",
    "# The following grabs all the images from the preprocessed_images folder, and create thumbnail to reduce the data size \n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# create three lists(all, left, right) for the model later\n",
    "all_images = []\n",
    "all_images_left = []\n",
    "all_images_right = []\n",
    "def get_pixels(values):\n",
    "    im = Image.open(f'./preprocessed_images/{values}')\n",
    "    name = values[:-4]\n",
    "    im.thumbnail((128,128))\n",
    "    all_images.append(im)\n",
    "    if name[-5] == 'r':\n",
    "        all_images_right.append(im)\n",
    "    else:\n",
    "        all_images_left.append(im)\n",
    "    return im\n",
    "\n",
    "df['pixel_data'] = df['filename'].apply(lambda x: get_pixels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffdfd147a60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# countplot to show the distribution of the dataset\n",
    "import seaborn as sns\n",
    "sns.countplot(df['y_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    2873\n",
       "D    1608\n",
       "O     708\n",
       "C     293\n",
       "G     284\n",
       "A     266\n",
       "M     232\n",
       "H     128\n",
       "Name: y_labels, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('filepath', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>...</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "      <th>pixel_data</th>\n",
       "      <th>y_labels</th>\n",
       "      <th>bin_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "\n",
       "  Left-Diagnostic Keywords Right-Diagnostic Keywords  N  D  G  ...  A  H  M  \\\n",
       "0                 cataract             normal fundus  0  0  0  ...  0  0  0   \n",
       "\n",
       "   O  labels                    target     filename  \\\n",
       "0  0   ['N']  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg   \n",
       "\n",
       "                                          pixel_data y_labels bin_labels  \n",
       "0  <PIL.JpegImagePlugin.JpegImageFile image mode=...        N          0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create two y labeling methods for different models later on\n",
    "def y_labels(label):\n",
    "    return label[2]\n",
    "\n",
    "def simplify(label):\n",
    "    if label[2] == 'N':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def without_n(label):\n",
    "    \n",
    "    \n",
    "df['y_labels'] = df['labels'].apply(lambda x: y_labels(x))\n",
    "df['bin_labels'] = df['labels'].apply(lambda x: simplify(x))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3519\n",
       "0    2873\n",
       "Name: bin_labels, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the data is balanced enough, seems ok in this case\n",
    "df['bin_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the image data into array \n",
    "for img in range(len(all_images)):\n",
    "    all_images[img] = image.img_to_array(all_images[img])\n",
    "    all_images[img] = all_images[img]/255\n",
    "image_array = np.array(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 128, 128, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in range(len(all_images_left)):\n",
    "    all_images_left[img] = image.img_to_array(all_images_left[img])\n",
    "for img in range(len(all_images_right)):\n",
    "    all_images_right[img] = image.img_to_array(all_images_right[img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array_l = np.array(all_images_left)\n",
    "image_array_r = np.array(all_images_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 128, 128, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 100, 100, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allim = []\n",
    "for i in range(len(df['filename'])):\n",
    "    img = image.load_img('./preprocessed_images/'+df['filename'][i],target_size=(100,100))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    allim.append(img)\n",
    "image_array2 = np.array(allim)\n",
    "image_array2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3198"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the index number where the left eye image starts\n",
    "y = df['y_labels'][3194:]\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "# x_train = np.array(all_images)\n",
    "# X_unprocessed = df['pixel_data']\n",
    "# transformer = ImageDataGenerator(rescale=3.0/255.)\n",
    "# X = transformer.flow_from_dataframe(df, x_col=X_unprocessed, batch_size=20, target_size=(128,128))\n",
    "# print(X.shape)\n",
    "# print(X[0])\n",
    "\n",
    "y = df['y_labels']\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = utils.to_categorical(encoded_y)\n",
    "\n",
    "binary_y = df['bin_labels']\n",
    "binary_y = utils.to_categorical(binary_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_array, dummy_y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4794, 128, 128, 3)\n",
      "(4794, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first model\n",
    "using softmax as the last activation function, num_classes should be changed when creating different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 126, 126, 25)      700       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 63, 63, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 61, 61, 50)        11300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 30, 30, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 45000)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               5760128   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 5,780,904\n",
      "Trainable params: 5,780,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "num_classes = 8\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(25,(3,3),\n",
    "              activation='relu',\n",
    "              input_shape=(128,128,3)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(50,(3,3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(num_classes, activation='softmax'))\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import pydotplus\n",
    "import pydot\n",
    "\n",
    "plot_model(cnn, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best accuracy for binary in this model is 55%, for multi-categories is around 46%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 1.6782 - accuracy: 0.4141 - precision: 0.4245 - recall: 0.0777 - val_loss: 1.5767 - val_accuracy: 0.4421 - val_precision: 0.3333 - val_recall: 0.0010\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 1.6023 - accuracy: 0.4415 - precision: 0.4810 - recall: 0.1022 - val_loss: 1.5541 - val_accuracy: 0.4421 - val_precision: 0.6111 - val_recall: 0.0115\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 1.5654 - accuracy: 0.4469 - precision: 0.4911 - recall: 0.1153 - val_loss: 1.5427 - val_accuracy: 0.4432 - val_precision: 0.5714 - val_recall: 0.1210\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 1.5557 - accuracy: 0.4475 - precision: 0.4862 - recall: 0.1153 - val_loss: 1.5392 - val_accuracy: 0.4421 - val_precision: 0.6667 - val_recall: 0.0292\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 1.5315 - accuracy: 0.4469 - precision: 0.5044 - recall: 0.1184 - val_loss: 1.5156 - val_accuracy: 0.4421 - val_precision: 0.5259 - val_recall: 0.1908\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 1.5167 - accuracy: 0.4545 - precision: 0.5163 - recall: 0.1278 - val_loss: 1.5259 - val_accuracy: 0.4421 - val_precision: 0.6061 - val_recall: 0.0417\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 1.5164 - accuracy: 0.4485 - precision: 0.5055 - recall: 0.1189 - val_loss: 1.5042 - val_accuracy: 0.4453 - val_precision: 0.5727 - val_recall: 0.1314\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 1.4927 - accuracy: 0.4571 - precision: 0.5293 - recall: 0.1319 - val_loss: 1.4721 - val_accuracy: 0.4567 - val_precision: 0.6209 - val_recall: 0.1178\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 1.4834 - accuracy: 0.4574 - precision: 0.5304 - recall: 0.1432 - val_loss: 1.4417 - val_accuracy: 0.4463 - val_precision: 0.7143 - val_recall: 0.0626\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 21s 168ms/step - loss: 1.4511 - accuracy: 0.4600 - precision: 0.5465 - recall: 0.1518 - val_loss: 1.4592 - val_accuracy: 0.4630 - val_precision: 0.5905 - val_recall: 0.1293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffbaddeaa30>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=30\n",
    "epochs=10\n",
    "\n",
    "img_rows, img_cols = 28,28\n",
    "\n",
    "\n",
    "cnn.fit(X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "       callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02430115, 0.05786459, 0.10312879, 0.21184193, 0.00414914,\n",
       "        0.02084046, 0.5095545 , 0.06831941],\n",
       "       [0.05840404, 0.04123365, 0.30181882, 0.03079767, 0.03055104,\n",
       "        0.01725152, 0.3846001 , 0.13534324],\n",
       "       [0.03921281, 0.03033204, 0.29216266, 0.03264115, 0.02628312,\n",
       "        0.01829009, 0.44780064, 0.11327754],\n",
       "       [0.04805551, 0.04086681, 0.29338983, 0.02723557, 0.02724729,\n",
       "        0.01001365, 0.42329398, 0.12989745],\n",
       "       [0.04961231, 0.04542085, 0.26962328, 0.0329733 , 0.02971705,\n",
       "        0.01101359, 0.43583518, 0.12580438]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = cnn.predict(X_test)\n",
    "y_predict[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-89-6dd94b610d60>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = cnn.predict_classes(X_test)\n",
    "y_predict[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = np.argmax(cnn.predict(X_test), axis=-1)\n",
    "y_predict[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13141426783479349"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in y_predict:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] >= 0.5:\n",
    "            i[j] = 1\n",
    "        else:\n",
    "            i[j] = 0\n",
    "count=0\n",
    "for i in range(len(y_predict)):\n",
    "    flag=True\n",
    "    for j in range(8):\n",
    "        if y_predict[i][j] == y_test[i][j]:\n",
    "            continue\n",
    "        else:\n",
    "            flag=False\n",
    "            break\n",
    "    if flag:\n",
    "        count+=1\n",
    "    \n",
    "count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16020025031289112"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in y_predict:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] == max(i):\n",
    "            i[j] = 1\n",
    "        else:\n",
    "            i[j] = 0\n",
    "count=0\n",
    "for i in range(len(y_predict)):\n",
    "    if np.where(y_predict[i] == 1) == np.where(y_test[i] == 1):\n",
    "        count+=1\n",
    "count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4560832791151594 0.9831697054698457 0.15577777777777777\n"
     ]
    }
   ],
   "source": [
    "# calculate only for normal eye\n",
    "y_predict = np.argmax(cnn.predict(X_test), axis=-1)\n",
    "y_test_arg = np.argmax(y_test, axis=-1)\n",
    "\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == 6:\n",
    "        if y_test_arg[i] == 6:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    else:\n",
    "        if y_test_arg[i] == 6:\n",
    "            fn+=1\n",
    "        else:\n",
    "            tn+=1\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f = precision*recall/((precision+recall)*2)\n",
    "print(precision, recall, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4555885791778564\n",
      "Test accuracy: 0.4612014889717102\n"
     ]
    }
   ],
   "source": [
    "score = cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The second model\n",
    "the very first model - using sigmoid as the last activation function, nodes are set to 8 currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 126, 126, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 254016)            0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                16257088  \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 16,263,560\n",
      "Trainable params: 16,263,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(128,128,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, CategoricalAccuracy\n",
    "bin_accu = BinaryAccuracy(dtype=None, threshold=0.5)\n",
    "cat_accu = CategoricalAccuracy()\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "48/48 [==============================] - 24s 493ms/step - loss: 1.6694 - accuracy: 0.4332\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 23s 481ms/step - loss: 1.5862 - accuracy: 0.4506\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 23s 478ms/step - loss: 1.5727 - accuracy: 0.4506\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 23s 481ms/step - loss: 1.5612 - accuracy: 0.4506\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 24s 495ms/step - loss: 1.5513 - accuracy: 0.4506\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 24s 510ms/step - loss: 1.5451 - accuracy: 0.4506\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 26s 551ms/step - loss: 1.5350 - accuracy: 0.4506\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 24s 492ms/step - loss: 1.5313 - accuracy: 0.4506\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 24s 491ms/step - loss: 1.5211 - accuracy: 0.4506\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 24s 497ms/step - loss: 1.5171 - accuracy: 0.4506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffadf334e80>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08385481852315395"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "for i in y_predict:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] >= 0.5:\n",
    "            i[j] = 1\n",
    "        else:\n",
    "            i[j] = 0\n",
    "count=0\n",
    "for i in range(len(y_predict)):\n",
    "    flag=True\n",
    "    for j in range(8):\n",
    "        if y_predict[i][j] == y_test[i][j]:\n",
    "            continue\n",
    "        else:\n",
    "            flag=False\n",
    "            break\n",
    "    if flag:\n",
    "        count+=1\n",
    "    \n",
    "count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44618272841051315"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_arg = np.argmax(y_test, axis=-1)\n",
    "\n",
    "count=0\n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == y_test_arg[i]:\n",
    "        count+=1\n",
    "count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44618272841051315 1.0 0.15426222414539162\n"
     ]
    }
   ],
   "source": [
    "# calculate only for normal eye\n",
    "y_predict = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_arg = np.argmax(y_test, axis=-1)\n",
    "\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == 6:\n",
    "        if y_test_arg[i] == 6:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    else:\n",
    "        if y_test_arg[i] == 6:\n",
    "            fn+=1\n",
    "        else:\n",
    "            tn+=1\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f = precision*recall/((precision+recall)*2)\n",
    "print(precision, recall, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.532153844833374\n",
      "Test accuracy: 0.4461827278137207\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The third model\n",
    "reference - https://www.kaggle.com/roobansappani/cataract-detection\n",
    "saw this notebook and it got 93% of accuracy, so I decided to test on the binary case\n",
    "the model takes a LONG time to fit(check the seconds), I only train for 10 epochs in the following model\n",
    "### got an accuracy of 63%, could possibly get higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "vgg = VGG19(weights = \"imagenet\", include_top = False, input_shape=(128, 128, 3))\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(vgg)\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(64, activation = 'relu'))\n",
    "model_1.add(Dense(2,activation = \"softmax\"))\n",
    "model_1.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 176s 6s/step - loss: 0.6892 - accuracy: 0.5437 - precision: 0.5437 - recall: 0.5437 - val_loss: 0.6793 - val_accuracy: 0.5902 - val_precision: 0.5902 - val_recall: 0.5902\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 176s 6s/step - loss: 0.6716 - accuracy: 0.5739 - precision: 0.5739 - recall: 0.5739 - val_loss: 0.6759 - val_accuracy: 0.5673 - val_precision: 0.5673 - val_recall: 0.5673\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 177s 6s/step - loss: 0.6739 - accuracy: 0.5718 - precision: 0.5718 - recall: 0.5718 - val_loss: 0.6813 - val_accuracy: 0.5485 - val_precision: 0.5485 - val_recall: 0.5485\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 177s 6s/step - loss: 0.6578 - accuracy: 0.5911 - precision: 0.5911 - recall: 0.5911 - val_loss: 0.6924 - val_accuracy: 0.5652 - val_precision: 0.5652 - val_recall: 0.5652\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 176s 6s/step - loss: 0.6514 - accuracy: 0.5958 - precision: 0.5958 - recall: 0.5958 - val_loss: 0.6774 - val_accuracy: 0.5589 - val_precision: 0.5589 - val_recall: 0.5589\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 175s 6s/step - loss: 0.6453 - accuracy: 0.6110 - precision: 0.6110 - recall: 0.6110 - val_loss: 0.6647 - val_accuracy: 0.5871 - val_precision: 0.5871 - val_recall: 0.5871\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 175s 6s/step - loss: 0.6365 - accuracy: 0.6229 - precision: 0.6229 - recall: 0.6229 - val_loss: 0.6642 - val_accuracy: 0.5954 - val_precision: 0.5954 - val_recall: 0.5954\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 175s 6s/step - loss: 0.6361 - accuracy: 0.6211 - precision: 0.6211 - recall: 0.6211 - val_loss: 0.6720 - val_accuracy: 0.5798 - val_precision: 0.5798 - val_recall: 0.5798\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 177s 6s/step - loss: 0.6361 - accuracy: 0.6162 - precision: 0.6162 - recall: 0.6162 - val_loss: 0.6642 - val_accuracy: 0.5808 - val_precision: 0.5808 - val_recall: 0.5808\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 174s 6s/step - loss: 0.6262 - accuracy: 0.6329 - precision: 0.6329 - recall: 0.6329 - val_loss: 0.6702 - val_accuracy: 0.5839 - val_precision: 0.5839 - val_recall: 0.5839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff5f9fd2070>"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train, y_train, \n",
    "            validation_split = 0.2, \n",
    "            epochs = 10,\n",
    "            batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The try model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "num_classes = 8\n",
    "\n",
    "cnn2 = Sequential()\n",
    "cnn2.add(Conv2D(25,(3,3),\n",
    "              activation='relu',\n",
    "              input_shape=(100,100,3)))\n",
    "cnn2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn2.add(Conv2D(50,(3,3), activation='relu'))\n",
    "cnn2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn2.add(Flatten())\n",
    "cnn2.add(Dense(128, activation='relu'))\n",
    "cnn2.add(Dropout(0.3))\n",
    "cnn2.add(Dense(64, activation='relu'))\n",
    "cnn2.add(Dropout(0.3))\n",
    "cnn2.add(Dense(num_classes, activation='softmax'))\n",
    "cnn2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 1.6391 - accuracy: 0.4360 - precision: 0.4606 - recall: 0.0975 - val_loss: 1.5869 - val_accuracy: 0.4432 - val_precision: 0.3750 - val_recall: 0.0031\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 14s 107ms/step - loss: 1.5741 - accuracy: 0.4506 - precision: 0.4883 - recall: 0.1199 - val_loss: 1.5452 - val_accuracy: 0.4432 - val_precision: 0.6000 - val_recall: 0.0282\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 13s 103ms/step - loss: 1.5523 - accuracy: 0.4579 - precision: 0.4900 - recall: 0.1150 - val_loss: 1.5254 - val_accuracy: 0.4463 - val_precision: 0.6618 - val_recall: 0.0469\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 1.5355 - accuracy: 0.4540 - precision: 0.5167 - recall: 0.1452 - val_loss: 1.5162 - val_accuracy: 0.4463 - val_precision: 0.6809 - val_recall: 0.0334\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 14s 106ms/step - loss: 1.5094 - accuracy: 0.4553 - precision: 0.5051 - recall: 0.1291 - val_loss: 1.5143 - val_accuracy: 0.4463 - val_precision: 0.5882 - val_recall: 0.0626\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 14s 111ms/step - loss: 1.4983 - accuracy: 0.4532 - precision: 0.5147 - recall: 0.1327 - val_loss: 1.4915 - val_accuracy: 0.4463 - val_precision: 0.6019 - val_recall: 0.0647\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 1.4785 - accuracy: 0.4584 - precision: 0.5255 - recall: 0.1450 - val_loss: 1.4800 - val_accuracy: 0.4515 - val_precision: 0.5134 - val_recall: 0.3003\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 1.4675 - accuracy: 0.4628 - precision: 0.5170 - recall: 0.1465 - val_loss: 1.4537 - val_accuracy: 0.4505 - val_precision: 0.6619 - val_recall: 0.0959\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 14s 112ms/step - loss: 1.4344 - accuracy: 0.4644 - precision: 0.5453 - recall: 0.1679 - val_loss: 1.5156 - val_accuracy: 0.4599 - val_precision: 0.5137 - val_recall: 0.2742\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 13s 104ms/step - loss: 1.4318 - accuracy: 0.4668 - precision: 0.5595 - recall: 0.1619 - val_loss: 1.4367 - val_accuracy: 0.4578 - val_precision: 0.6433 - val_recall: 0.1053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffbec5ef520>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=30\n",
    "epochs=10\n",
    "\n",
    "img_rows, img_cols = 28,28\n",
    "\n",
    "\n",
    "cnn2.fit(X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "       callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4350862503051758\n",
      "Test accuracy: 0.4524405598640442\n"
     ]
    }
   ],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel('./ODIR-5K/ODIR-5K/data.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>1_left.jpg</td>\n",
       "      <td>1_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>2_left.jpg</td>\n",
       "      <td>2_right.jpg</td>\n",
       "      <td>laser spotï¼Œmoderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>Male</td>\n",
       "      <td>3_left.jpg</td>\n",
       "      <td>3_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>branch retinal artery occlusion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>4686</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>4686_left.jpg</td>\n",
       "      <td>4686_right.jpg</td>\n",
       "      <td>severe nonproliferative retinopathy</td>\n",
       "      <td>proliferative diabetic retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>4688</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>4688_left.jpg</td>\n",
       "      <td>4688_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>4689</td>\n",
       "      <td>54</td>\n",
       "      <td>Male</td>\n",
       "      <td>4689_left.jpg</td>\n",
       "      <td>4689_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>4690</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>4690_left.jpg</td>\n",
       "      <td>4690_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>4784</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>4784_left.jpg</td>\n",
       "      <td>4784_right.jpg</td>\n",
       "      <td>hypertensive retinopathyï¼Œage-related macular d...</td>\n",
       "      <td>hypertensive retinopathyï¼Œage-related macular d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Patient Age Patient Sex    Left-Fundus    Right-Fundus  \\\n",
       "0        0           69      Female     0_left.jpg     0_right.jpg   \n",
       "1        1           57        Male     1_left.jpg     1_right.jpg   \n",
       "2        2           42        Male     2_left.jpg     2_right.jpg   \n",
       "3        3           66        Male     3_left.jpg     3_right.jpg   \n",
       "4        4           53        Male     4_left.jpg     4_right.jpg   \n",
       "...    ...          ...         ...            ...             ...   \n",
       "3495  4686           63        Male  4686_left.jpg  4686_right.jpg   \n",
       "3496  4688           42        Male  4688_left.jpg  4688_right.jpg   \n",
       "3497  4689           54        Male  4689_left.jpg  4689_right.jpg   \n",
       "3498  4690           57        Male  4690_left.jpg  4690_right.jpg   \n",
       "3499  4784           58        Male  4784_left.jpg  4784_right.jpg   \n",
       "\n",
       "                               Left-Diagnostic Keywords  \\\n",
       "0                                              cataract   \n",
       "1                                         normal fundus   \n",
       "2     laser spotï¼Œmoderate non proliferative retinopathy   \n",
       "3                                         normal fundus   \n",
       "4                           macular epiretinal membrane   \n",
       "...                                                 ...   \n",
       "3495                severe nonproliferative retinopathy   \n",
       "3496             moderate non proliferative retinopathy   \n",
       "3497                  mild nonproliferative retinopathy   \n",
       "3498                  mild nonproliferative retinopathy   \n",
       "3499  hypertensive retinopathyï¼Œage-related macular d...   \n",
       "\n",
       "                              Right-Diagnostic Keywords  N  D  G  C  A  H  M  \\\n",
       "0                                         normal fundus  0  0  0  1  0  0  0   \n",
       "1                                         normal fundus  1  0  0  0  0  0  0   \n",
       "2                moderate non proliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3                       branch retinal artery occlusion  0  0  0  0  0  0  0   \n",
       "4                     mild nonproliferative retinopathy  0  1  0  0  0  0  0   \n",
       "...                                                 ... .. .. .. .. .. .. ..   \n",
       "3495                 proliferative diabetic retinopathy  0  1  0  0  0  0  0   \n",
       "3496             moderate non proliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3497                                      normal fundus  0  1  0  0  0  0  0   \n",
       "3498                  mild nonproliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3499  hypertensive retinopathyï¼Œage-related macular d...  0  0  0  0  1  1  0   \n",
       "\n",
       "      O  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  \n",
       "...  ..  \n",
       "3495  0  \n",
       "3496  0  \n",
       "3497  0  \n",
       "3498  0  \n",
       "3499  0  \n",
       "\n",
       "[3500 rows x 15 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
