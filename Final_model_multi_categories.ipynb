{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>filepath</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_right.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "\n",
       "  Left-Diagnostic Keywords Right-Diagnostic Keywords  N  D  G  C  A  H  M  O  \\\n",
       "0                 cataract             normal fundus  0  0  0  1  0  0  0  0   \n",
       "\n",
       "                                            filepath labels  \\\n",
       "0  ../input/ocular-disease-recognition-odir5k/ODI...  ['N']   \n",
       "\n",
       "                     target     filename  \n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['filename'] == '0_right.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>filepath</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['D']</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4_right.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/ocular-disease-recognition-odir5k/ODI...</td>\n",
       "      <td>['O']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>4_left.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "3      4           53        Male  4_left.jpg  4_right.jpg   \n",
       "3197   4           53        Male  4_left.jpg  4_right.jpg   \n",
       "\n",
       "         Left-Diagnostic Keywords          Right-Diagnostic Keywords  N  D  G  \\\n",
       "3     macular epiretinal membrane  mild nonproliferative retinopathy  0  1  0   \n",
       "3197  macular epiretinal membrane  mild nonproliferative retinopathy  0  1  0   \n",
       "\n",
       "      C  A  H  M  O                                           filepath labels  \\\n",
       "3     0  0  0  0  1  ../input/ocular-disease-recognition-odir5k/ODI...  ['D']   \n",
       "3197  0  0  0  0  1  ../input/ocular-disease-recognition-odir5k/ODI...  ['O']   \n",
       "\n",
       "                        target     filename  \n",
       "3     [0, 1, 0, 0, 0, 0, 0, 0]  4_right.jpg  \n",
       "3197  [0, 0, 0, 0, 0, 0, 0, 1]   4_left.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is to show that the dataset separate two image files in two rows\n",
    "df[df['Left-Fundus'] == '4_left.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the string slicing \n",
    "x = df['filename']\n",
    "name = x[0][:-4]\n",
    "name[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test imputing the image\n",
    "# y = df['filename'][0]\n",
    "# im = Image.open(f'./0_right_thumbnail.jpg')\n",
    "# list(im.getdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./preprocessed_images/{x}', 'r') as f:\n",
    "#     print(f)\n",
    "\n",
    "# The following grabs all the images from the preprocessed_images folder, and create thumbnail to reduce the data size \n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# create three lists(all, left, right) for the model later\n",
    "all_images = []\n",
    "all_images_left = []\n",
    "all_images_right = []\n",
    "def get_pixels(values):\n",
    "    im = Image.open(f'./preprocessed_images/{values}')\n",
    "    name = values[:-4]\n",
    "    im.thumbnail((128,128))\n",
    "    all_images.append(im)\n",
    "    if name[-5] == 'r':\n",
    "        all_images_right.append(im)\n",
    "    else:\n",
    "        all_images_left.append(im)\n",
    "    return im\n",
    "\n",
    "df['pixel_data'] = df['filename'].apply(lambda x: get_pixels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffdfd147a60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# countplot to show the distribution of the dataset\n",
    "import seaborn as sns\n",
    "sns.countplot(df['y_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('filepath', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>...</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>labels</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "      <th>pixel_data</th>\n",
       "      <th>y_labels</th>\n",
       "      <th>bin_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['N']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Patient Age Patient Sex Left-Fundus Right-Fundus  \\\n",
       "0   0           69      Female  0_left.jpg  0_right.jpg   \n",
       "\n",
       "  Left-Diagnostic Keywords Right-Diagnostic Keywords  N  D  G  ...  A  H  M  \\\n",
       "0                 cataract             normal fundus  0  0  0  ...  0  0  0   \n",
       "\n",
       "   O  labels                    target     filename  \\\n",
       "0  0   ['N']  [1, 0, 0, 0, 0, 0, 0, 0]  0_right.jpg   \n",
       "\n",
       "                                          pixel_data y_labels bin_labels  \n",
       "0  <PIL.JpegImagePlugin.JpegImageFile image mode=...        N          0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create two y labeling methods for different models later on\n",
    "def y_labels(label):\n",
    "    return label[2]\n",
    "\n",
    "def simplify(label):\n",
    "    if label[2] == 'N':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "df['y_labels'] = df['labels'].apply(lambda x: y_labels(x))\n",
    "df['bin_labels'] = df['labels'].apply(lambda x: simplify(x))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3519\n",
       "0    2873\n",
       "Name: bin_labels, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the data is balanced enough, seems ok in this case\n",
    "df['bin_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the image data into array \n",
    "for img in range(len(all_images)):\n",
    "    all_images[img] = image.img_to_array(all_images[img])\n",
    "    all_images[img] = all_images[img]/255\n",
    "image_array = np.array(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 128, 128, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in range(len(all_images_left)):\n",
    "    all_images_left[img] = image.img_to_array(all_images_left[img])\n",
    "for img in range(len(all_images_right)):\n",
    "    all_images_right[img] = image.img_to_array(all_images_right[img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array_l = np.array(all_images_left)\n",
    "image_array_r = np.array(all_images_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6392, 128, 128, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3198"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the index number where the left eye image starts\n",
    "y = df['y_labels'][3194:]\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "# x_train = np.array(all_images)\n",
    "# X_unprocessed = df['pixel_data']\n",
    "# transformer = ImageDataGenerator(rescale=3.0/255.)\n",
    "# X = transformer.flow_from_dataframe(df, x_col=X_unprocessed, batch_size=20, target_size=(128,128))\n",
    "# print(X.shape)\n",
    "# print(X[0])\n",
    "\n",
    "y = df['y_labels']\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = utils.to_categorical(encoded_y)\n",
    "\n",
    "binary_y = df['bin_labels']\n",
    "binary_y = utils.to_categorical(binary_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_array, dummy_y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4794, 128, 128, 3)\n",
      "(4794, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first model\n",
    "using softmax as the last activation function, num_classes should be changed when creating different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "num_classes = 8\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(25,(3,3),\n",
    "              activation='relu',\n",
    "              input_shape=(128,128,3)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(50,(3,3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(num_classes, activation='softmax'))\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best accuracy for binary in this model is 55%, for multi-categories is around 46%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 1.7090 - accuracy: 0.4130 - precision: 0.4381 - recall: 0.0756 - val_loss: 1.6047 - val_accuracy: 0.4463 - val_precision: 0.5100 - val_recall: 0.1335\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 20s 160ms/step - loss: 1.5916 - accuracy: 0.4464 - precision: 0.4782 - recall: 0.1087 - val_loss: 1.6020 - val_accuracy: 0.4463 - val_precision: 0.5040 - val_recall: 0.1303\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 21s 162ms/step - loss: 1.5537 - accuracy: 0.4542 - precision: 0.5228 - recall: 0.1257 - val_loss: 1.5851 - val_accuracy: 0.4463 - val_precision: 0.5368 - val_recall: 0.1522\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 21s 162ms/step - loss: 1.5490 - accuracy: 0.4550 - precision: 0.5124 - recall: 0.1288 - val_loss: 1.5886 - val_accuracy: 0.4463 - val_precision: 0.6250 - val_recall: 0.0052\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 1.5262 - accuracy: 0.4602 - precision: 0.5391 - recall: 0.1278 - val_loss: 1.5516 - val_accuracy: 0.4494 - val_precision: 0.5263 - val_recall: 0.0104\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 1.4956 - accuracy: 0.4613 - precision: 0.5705 - recall: 0.1614 - val_loss: 1.5461 - val_accuracy: 0.4536 - val_precision: 0.4860 - val_recall: 0.2534\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 1.4793 - accuracy: 0.4673 - precision: 0.5422 - recall: 0.1643 - val_loss: 1.5204 - val_accuracy: 0.4578 - val_precision: 0.5429 - val_recall: 0.1387\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 1.4534 - accuracy: 0.4688 - precision: 0.5641 - recall: 0.1778 - val_loss: 1.4874 - val_accuracy: 0.4745 - val_precision: 0.6010 - val_recall: 0.1303\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 1.4328 - accuracy: 0.4777 - precision: 0.5705 - recall: 0.1815 - val_loss: 1.5036 - val_accuracy: 0.4640 - val_precision: 0.5206 - val_recall: 0.2367\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 1.4154 - accuracy: 0.4793 - precision: 0.6055 - recall: 0.1997 - val_loss: 1.4885 - val_accuracy: 0.4724 - val_precision: 0.5070 - val_recall: 0.1502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffc54daa190>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=30\n",
    "epochs=10\n",
    "\n",
    "img_rows, img_cols = 28,28\n",
    "\n",
    "\n",
    "cnn.fit(X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "       callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02347597, 0.01107777, 0.34688357, ..., 0.00296472, 0.47711483,\n",
       "        0.11834483],\n",
       "       [0.04279061, 0.03282528, 0.28677475, ..., 0.00549726, 0.44734013,\n",
       "        0.14531823],\n",
       "       [0.04027262, 0.03942206, 0.37331802, ..., 0.00786979, 0.26189095,\n",
       "        0.14301333],\n",
       "       ...,\n",
       "       [0.03280005, 0.01540472, 0.3409007 , ..., 0.00657046, 0.4616018 ,\n",
       "        0.11205833],\n",
       "       [0.0330701 , 0.01647053, 0.29329756, ..., 0.0037999 , 0.51911855,\n",
       "        0.10746774],\n",
       "       [0.05589647, 0.04143127, 0.19282553, ..., 0.01750824, 0.549856  ,\n",
       "        0.07983497]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44680851063829785"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in y_predict:\n",
    "#     for j in range(len(i)):\n",
    "#         if i[j] == max(i):\n",
    "#             i[j] = 1\n",
    "#         else:\n",
    "#             i[j] = 0\n",
    "# count=0\n",
    "# for i in range(len(y_predict)):\n",
    "#     if np.where(y_predict[i] == 1) == np.where(y_test[i] == 1):\n",
    "#         count+=1\n",
    "# count/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4936745166778564\n",
      "Test accuracy: 0.44680851697921753\n"
     ]
    }
   ],
   "source": [
    "score = cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The second model\n",
    "the very first model - using sigmoid as the last activation function, nodes are set to 8 currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(128,128,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "215/215 [==============================] - 22s 103ms/step - loss: 4.5205 - accuracy: 0.2478\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 23s 105ms/step - loss: 4.5205 - accuracy: 0.2487\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 23s 108ms/step - loss: 4.5205 - accuracy: 0.2487\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 25s 116ms/step - loss: 4.5205 - accuracy: 0.2487\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 23s 109ms/step - loss: 4.5205 - accuracy: 0.2487\n",
      "Epoch 6/10\n",
      " 34/215 [===>..........................] - ETA: 19s - loss: 4.5926 - accuracy: 0.2515"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-22bfe5e00875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The third model\n",
    "reference - https://www.kaggle.com/roobansappani/cataract-detection\n",
    "saw this notebook and it got 93% of accuracy, so I decided to test on the binary case\n",
    "the model takes a LONG time to fit(check the seconds), I only train for 10 epochs in the following model\n",
    "### got an accuracy of 63%, could possibly get higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "vgg = VGG19(weights = \"imagenet\", include_top = False, input_shape=(128, 128, 3))\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(vgg)\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(64, activation = 'relu'))\n",
    "model_1.add(Dense(2,activation = \"softmax\"))\n",
    "model_1.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 176s 6s/step - loss: 0.6892 - accuracy: 0.5437 - precision: 0.5437 - recall: 0.5437 - val_loss: 0.6793 - val_accuracy: 0.5902 - val_precision: 0.5902 - val_recall: 0.5902\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 176s 6s/step - loss: 0.6716 - accuracy: 0.5739 - precision: 0.5739 - recall: 0.5739 - val_loss: 0.6759 - val_accuracy: 0.5673 - val_precision: 0.5673 - val_recall: 0.5673\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 177s 6s/step - loss: 0.6739 - accuracy: 0.5718 - precision: 0.5718 - recall: 0.5718 - val_loss: 0.6813 - val_accuracy: 0.5485 - val_precision: 0.5485 - val_recall: 0.5485\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 177s 6s/step - loss: 0.6578 - accuracy: 0.5911 - precision: 0.5911 - recall: 0.5911 - val_loss: 0.6924 - val_accuracy: 0.5652 - val_precision: 0.5652 - val_recall: 0.5652\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 176s 6s/step - loss: 0.6514 - accuracy: 0.5958 - precision: 0.5958 - recall: 0.5958 - val_loss: 0.6774 - val_accuracy: 0.5589 - val_precision: 0.5589 - val_recall: 0.5589\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 175s 6s/step - loss: 0.6453 - accuracy: 0.6110 - precision: 0.6110 - recall: 0.6110 - val_loss: 0.6647 - val_accuracy: 0.5871 - val_precision: 0.5871 - val_recall: 0.5871\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 175s 6s/step - loss: 0.6365 - accuracy: 0.6229 - precision: 0.6229 - recall: 0.6229 - val_loss: 0.6642 - val_accuracy: 0.5954 - val_precision: 0.5954 - val_recall: 0.5954\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 175s 6s/step - loss: 0.6361 - accuracy: 0.6211 - precision: 0.6211 - recall: 0.6211 - val_loss: 0.6720 - val_accuracy: 0.5798 - val_precision: 0.5798 - val_recall: 0.5798\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 177s 6s/step - loss: 0.6361 - accuracy: 0.6162 - precision: 0.6162 - recall: 0.6162 - val_loss: 0.6642 - val_accuracy: 0.5808 - val_precision: 0.5808 - val_recall: 0.5808\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 174s 6s/step - loss: 0.6262 - accuracy: 0.6329 - precision: 0.6329 - recall: 0.6329 - val_loss: 0.6702 - val_accuracy: 0.5839 - val_precision: 0.5839 - val_recall: 0.5839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff5f9fd2070>"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train, y_train, \n",
    "            validation_split = 0.2, \n",
    "            epochs = 10,\n",
    "            batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel('./ODIR-5K/ODIR-5K/data.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>Left-Diagnostic Keywords</th>\n",
       "      <th>Right-Diagnostic Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>1_left.jpg</td>\n",
       "      <td>1_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>2_left.jpg</td>\n",
       "      <td>2_right.jpg</td>\n",
       "      <td>laser spot，moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>Male</td>\n",
       "      <td>3_left.jpg</td>\n",
       "      <td>3_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>branch retinal artery occlusion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>macular epiretinal membrane</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>4686</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>4686_left.jpg</td>\n",
       "      <td>4686_right.jpg</td>\n",
       "      <td>severe nonproliferative retinopathy</td>\n",
       "      <td>proliferative diabetic retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>4688</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>4688_left.jpg</td>\n",
       "      <td>4688_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>4689</td>\n",
       "      <td>54</td>\n",
       "      <td>Male</td>\n",
       "      <td>4689_left.jpg</td>\n",
       "      <td>4689_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>4690</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>4690_left.jpg</td>\n",
       "      <td>4690_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>4784</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>4784_left.jpg</td>\n",
       "      <td>4784_right.jpg</td>\n",
       "      <td>hypertensive retinopathy，age-related macular d...</td>\n",
       "      <td>hypertensive retinopathy，age-related macular d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Patient Age Patient Sex    Left-Fundus    Right-Fundus  \\\n",
       "0        0           69      Female     0_left.jpg     0_right.jpg   \n",
       "1        1           57        Male     1_left.jpg     1_right.jpg   \n",
       "2        2           42        Male     2_left.jpg     2_right.jpg   \n",
       "3        3           66        Male     3_left.jpg     3_right.jpg   \n",
       "4        4           53        Male     4_left.jpg     4_right.jpg   \n",
       "...    ...          ...         ...            ...             ...   \n",
       "3495  4686           63        Male  4686_left.jpg  4686_right.jpg   \n",
       "3496  4688           42        Male  4688_left.jpg  4688_right.jpg   \n",
       "3497  4689           54        Male  4689_left.jpg  4689_right.jpg   \n",
       "3498  4690           57        Male  4690_left.jpg  4690_right.jpg   \n",
       "3499  4784           58        Male  4784_left.jpg  4784_right.jpg   \n",
       "\n",
       "                               Left-Diagnostic Keywords  \\\n",
       "0                                              cataract   \n",
       "1                                         normal fundus   \n",
       "2     laser spot，moderate non proliferative retinopathy   \n",
       "3                                         normal fundus   \n",
       "4                           macular epiretinal membrane   \n",
       "...                                                 ...   \n",
       "3495                severe nonproliferative retinopathy   \n",
       "3496             moderate non proliferative retinopathy   \n",
       "3497                  mild nonproliferative retinopathy   \n",
       "3498                  mild nonproliferative retinopathy   \n",
       "3499  hypertensive retinopathy，age-related macular d...   \n",
       "\n",
       "                              Right-Diagnostic Keywords  N  D  G  C  A  H  M  \\\n",
       "0                                         normal fundus  0  0  0  1  0  0  0   \n",
       "1                                         normal fundus  1  0  0  0  0  0  0   \n",
       "2                moderate non proliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3                       branch retinal artery occlusion  0  0  0  0  0  0  0   \n",
       "4                     mild nonproliferative retinopathy  0  1  0  0  0  0  0   \n",
       "...                                                 ... .. .. .. .. .. .. ..   \n",
       "3495                 proliferative diabetic retinopathy  0  1  0  0  0  0  0   \n",
       "3496             moderate non proliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3497                                      normal fundus  0  1  0  0  0  0  0   \n",
       "3498                  mild nonproliferative retinopathy  0  1  0  0  0  0  0   \n",
       "3499  hypertensive retinopathy，age-related macular d...  0  0  0  0  1  1  0   \n",
       "\n",
       "      O  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  \n",
       "...  ..  \n",
       "3495  0  \n",
       "3496  0  \n",
       "3497  0  \n",
       "3498  0  \n",
       "3499  0  \n",
       "\n",
       "[3500 rows x 15 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
